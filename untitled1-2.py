# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Gp7mwB_hjMn38NT6vat3Ts8eThYh-HOV
"""

from google.colab import files

uploaded = files.upload()

!pip install scikit-learn

import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

data = pd.read_csv(student-mat.csv)  # Replace 'your_dataset.csv' with the actual file name



from google.colab import files

uploaded = files.upload()

data = pd.read_csv('student-mat.csv')  # Replace 'your_dataset.csv' with the actual file name

print(data.head())

X = data.drop('final_grade_column', axis=1)  # Replace 'final_grade_column' with the actual target variable
y = data['final_grade_column']

# Replace 'final_grade_column' with the actual target variable
y = data['G3']
X = data.drop('G3', axis=1)

# Assuming 'data' is your DataFrame
print(data.columns)

# Replace 'G3' with the actual target variable column name
y = data['G3']
X = data.drop('G3', axis=1)

print(data.head())

import pandas as pd
from io import StringIO

# Assuming 'data_str' contains the content of your CSV file as a string
data_str = """
school;sex;age;address;famsize;Pstatus;Medu;Fedu;Mjob;Fjob;reason;guardian;traveltime;studytime;failures;schoolsup;famsup;paid;activities;nursery;higher;internet;romantic;famrel;freetime;goout;Dalc;Walc;health;absences;G1;G2;G3
GP;"F";18;"U";"GT3";"A";4;4;"at_home";"teacher";"course";"mother";2;2;0;"yes";"no";"no";"no";"yes";"yes";"no";"no";4;3;4;1;1;3;"4";"3";"6";"5";"6"
GP;"F";17;"U";"GT3";"T";1;1;"at_home";"other";"course";"father";1;2;0;"no";"yes";"no";"no";"no";"yes";"yes";"no";5;3;3;1;1;3;"2";"3";"5";"5";"5"
GP;"F";15;"U";"LE3";"T";1;1;"at_home";"other";"other";"mother";1;2;3;"yes";"no";"yes";"no";"yes";"yes";"yes";"no";4;3;2;2;3;3;"6";"5";"8";"10";"10"
GP;"F";15;"U";"GT3";"T";4;2;"health";"services";"home";"mother";1;3;0;"no";"yes";"yes";"yes";"yes";"yes";"yes";"no";3;2;2;1;1;5;"0";"7";"15";"14";"15"
GP;"F";16

import pandas as pd
from io import StringIO

# Assuming 'data_str' contains the content of your CSV file as a string
data_str = """
school;sex;age;address;famsize;Pstatus;Medu;Fedu;Mjob;Fjob;reason;guardian;traveltime;studytime;failures;schoolsup;famsup;paid;activities;nursery;higher;internet;romantic;famrel;freetime;goout;Dalc;Walc;health;absences;G1;G2;G3
GP;"F";18;"U";"GT3";"A";4;4;"at_home";"teacher";"course";"mother";2;2;0;"yes";"no";"no";"no";"yes";"yes";"no";"no";4;3;4;1;1;3;"4";"3";"6";"5";"6"
GP;"F";17;"U";"GT3";"T";1;1;"at_home";"other";"course";"father";1;2;0;"no";"yes";"no";"no";"no";"yes";"yes";"no";5;3;3;1;1;3;"2";"3";"5";"5";"5"
GP;"F";15;"U";"LE3";"T";1;1;"at_home";"other";"other";"mother";1;2;3;"yes";"no";"yes";"no";"yes";"yes";"yes";"no";4;3;2;2;3;3;"6";"5";"8";"10";"10"
GP;"F";15;"U";"GT3";"T";4;2;"health";"services";"home";"mother";1;3;0;"no";"yes";"yes";"yes";"yes";"yes";"yes";"no";3;2;2;1;1;5;"0";"7";"15";"14";"15"
GP;"F";16;"U";"GT3";"T";3;3;"other";"other";"home";"father";1;2;0;"no";"yes";"yes";"no";"yes";"yes";"no";"no";4;3;2;1;2;5;"0";"8";"6";"10";"10"
"""

# Use StringIO to convert the string to a file-like object
data = pd.read_csv(StringIO(data_str), sep=';', quotechar='"')

# Now you can access the 'G3' column
print(data['G3'])

# Replace 'G3' with the actual target variable column name
y = data['G3']
X = data.drop('G3', axis=1)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = RandomForestClassifier()
model.fit(X_train, y_train)

X_encoded = pd.get_dummies(X, drop_first=True)

X_encoded = X_encoded.fillna(0)  # Replace missing values with 0, you may need a different strategy based on your data

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)

from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier()
model.fit(X_train, y_train)

feature_importances = model.feature_importances_

feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})

# Check the lengths of X.columns and feature_importances
print(len(X.columns), len(feature_importances))

# Assuming you have already trained a RandomForestClassifier and obtained feature_importances
# Ensure that X represents the same features used during model training
X = data.drop('G3', axis=1)  # Adjust based on your actual target variable

# Check the lengths
print(len(X.columns), len(feature_importances))

# If lengths match, proceed with creating the feature importance DataFrame
feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})

# Assuming you have already trained a RandomForestClassifier and obtained feature_importances
feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})

print(feature_importances)

print(X)

print(X.columns)

# Assuming you have resolved the mismatch issue and lengths now match
# Proceed with creating the feature importance DataFrame
feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})

# Assuming you have already trained a RandomForestClassifier and obtained feature_importances
# Ensure that X represents the same features used during model training
X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)

# Train the RandomForestClassifier
model = RandomForestClassifier()
model.fit(X_train, y_train)

# Extract feature importances
feature_importances = model.feature_importances_

# Create a DataFrame with feature importances
feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})

# Display the feature importance DataFrame
print(feature_importance_df)

# Optionally, you can sort the DataFrame by importance in descending order
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

# Display the sorted feature importance DataFrame
print("Sorted Feature Importance:")
print(feature_importance_df)

# Sort the dataframe by importance (if not sorted already)
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

# Print or visualize the results:
print(feature_importance_df)

# Create a bar plot for better visualization
import matplotlib.pyplot as plt

plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])
plt.xlabel('Importance')
plt.title('Feature Importance')
plt.show()