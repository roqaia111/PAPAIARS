# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WlznItLdLrVsZYMKBBCaodO_xn-uPjg7
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

data = pd.read_csv('student-mat.csv')

# Set a threshold for defining at-risk students (you can adjust this threshold based on your criteria)
threshold = 10  # For example, consider students with a final grade less than 10 as at-risk

# Create a binary column 'at_risk' based on the threshold
data['at_risk'] = (data['G3'] < threshold).astype(int)

print(data.columns)

print(data.head())

data = pd.read_csv('student-mat.csv')  # Replace with the correct file name

threshold = 9  # or any other threshold you want to use
data['at_risk'] = (data['G3'] < threshold).astype(int)

# Assuming the column name has leading or trailing spaces
data.columns = data.columns.str.strip()

# Assuming the column name has special characters
data.columns = data.columns.str.replace(';', '')

threshold = 10  # or any other threshold you want to use
data['at_risk'] = (data['G3'] < threshold).astype(int)

# Load the dataset with semicolon delimiter
data = pd.read_csv('student-mat.csv', delimiter=';')

# Check column names
print(data.columns)

# Print unique values in the 'G3' column
print(data['G3'].unique())

threshold = 20  # or any other threshold you want to use
data['at_risk'] = (data['G3'] < threshold).astype(int)

# Select features and target variable
features = ['G1', 'G2', 'absences', 'studytime']  # Add other features as needed
X = data[features]
y = data['at_risk']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a Random Forest classifier
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# Make predictions on the testing set
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')

print('Classification Report:')
print(classification_report(y_test, y_pred))

print('Confusion Matrix:')
print(confusion_matrix(y_test, y_pred))

# Analyze feature importances
feature_importances = model.feature_importances_
feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)
print(feature_importance_df)

from sklearn.ensemble import RandomForestClassifier

# Assuming 'G3' is the final grade column
threshold = 10  # Set your threshold based on the context
data['at_risk'] = (data['G3'] < threshold).astype(int)

# Alternatively, you can use the features identified in feature importance
# For example, if G2 and G1 are the most important features
# data['at_risk'] = ((data['G2'] < threshold) | (data['G1'] < threshold)).astype(int)

# Define features and target variable
X = data[['G1', 'G2', 'studytime', 'absences']]  # Adjust based on influential features
y = data['at_risk']

# Split the data into training and testing sets
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a model (Random Forest classifier used here)
model = RandomForestClassifier()
model.fit(X_train, y_train)

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Make predictions on the test set
y_pred = model.predict(X_test)

# Evaluate the model
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

from sklearn.model_selection import GridSearchCV

# Define hyperparameter grid
param_grid = {
    'n_estimators': [50, 100, 150],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Initialize the model
model = RandomForestClassifier()

# Perform Grid Search Cross Validation
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)
grid_search.fit(X_train, y_train)

# Print the best parameters
print("Best Parameters:", grid_search.best_params_)

from sklearn.metrics import f1_score

# Make predictions on the validation set
y_val_pred = model.predict(X_val)

# Initialize variables to store best threshold and F1-score
best_threshold = 0
best_f1_score = 0

# Iterate over different threshold values
for threshold in range(1, 20):
    threshold /= 20
    y_val_pred_binary = (y_val_pred > threshold).astype(int)
    f1 = f1_score(y_val, y_val_pred_binary)

    # Update best threshold if F1-score improves
    if f1 > best_f1_score:
        best_threshold = threshold
        best_f1_score = f1

print("Best Threshold:", best_threshold)

from sklearn.model_selection import train_test_split

# Assuming X and y are your features and target variable
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Make predictions on the validation set
y_val_pred = model.predict(X_val)

# Initialize variables to store best threshold and F1-score
best_threshold = 0
best_f1_score = 0

# Iterate over different threshold values
for threshold in range(1, 10):
    threshold /= 10
    y_val_pred_binary = (y_val_pred > threshold).astype(int)
    f1 = f1_score(y_val, y_val_pred_binary)

    # Update best threshold if F1-score improves
    if f1 > best_f1_score:
        best_threshold = threshold
        best_f1_score = f1

print("Best Threshold:", best_threshold)

# Assuming X_train and y_train are your training data
model.fit(X_train, y_train)

from sklearn.model_selection import train_test_split

# Assuming X and y are your features and target variable
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Assuming X_train and y_train are your training data
model.fit(X_train, y_train)

# Make predictions on the validation set
y_val_pred = model.predict(X_val)

# Initialize variables to store the best threshold and F1-score
best_threshold = 0
best_f1_score = 0

# Iterate over different threshold values
for threshold in range(1, 10):
    threshold /= 10
    y_val_pred_binary = (y_val_pred > threshold).astype(int)
    f1 = f1_score(y_val, y_val_pred_binary)

    # Update the best threshold if F1-score improves
    if f1 > best_f1_score:
        best_threshold = threshold
        best_f1_score = f1

print("Best Threshold:", best_threshold)

from sklearn.model_selection import cross_val_score

# Initialize the model with the best parameters
best_model = RandomForestClassifier(**grid_search.best_params_)

# Perform cross-validation
cv_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='accuracy')
print("Cross-Validation Scores:", cv_scores)
print("Mean Accuracy:", cv_scores.mean())

# Train the final model with the best parameters
best_model.fit(X_train, y_train)

# Make predictions on the test set
y_test_pred = best_model.predict(X_test)

# Evaluate the model on the test set
print("Final Model Accuracy:", accuracy_score(y_test, y_test_pred))
print("Classification Report:\n", classification_report(y_test, y_test_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_test_pred))